\chapter{Implementierung}
In diesem Kapitel wird auf Implementierungsdetails des Entwurfs eingegangen. Hierbei ist zu beachten, dass aus Platzgründen der vorliegende Code eventuell in gekürzter oder geänderter Form dargestellt wird und unvollständig ist. Dennoch verdeutlichen die Codebeispiele die wesentlichsten Details der Implementierung und sind gemäß des Entwurfs umgesetzt.

\section{Verarbeitungskette}
Die Verarbeitungskette ist ein Teil des \texttt{AudioHandlers} und einer der wichtigen Komponenten des Frameworks. Sie ist die Schnittstelle mit der anderen Klassen an der Audioverarbeitung teilnehmen können. Im folgenden Kapitel wird erörtert wie diese implementiert wurde.

\subsection{Interface für Audioverarbeitungsklassen}
Alle Audioverarbeitungsklassen müssen die abstrakte Klasse \texttt{AudioProcessor} implementieren, siehe Listening \ref{Code:AudioProcessor}.

\begin{lstlisting}[caption={Interface des AudioProcessors},label={Code:AudioProcessor}]
class AudioProcessor {
public:
	AudioProcessor(const std::string name);
	virtual unsigned int processInputData(void *inputBuffer, int inputBufferByteSize) = 0;
	virtual unsigned int processOutputData(void *outputBuffer,  int outputBufferByteSize) = 0;
}
\end{lstlisting}
Der Konstruktor in Zeile 4 erwartet als Parameter den Namen des Audioprozessors, damit dieser später eindeutig identifiziert werden kann. Die beiden Verarbeitungsmethoden in Zeile 5 und 6 sind virtuell, daher müssen alle Unterklassen diese implementieren. Diese Methoden stellen die Schnittstelle zur Audioverarbeitung dar und haben als Parameter jeweils den Buffer sowie die Buffergröße.

\subsection{An- und Abmeldeprozess im AudioHandler}
Listening \ref{Code:AudioHandlerAdd} zeigt die Schnittstelle zum An- und Abmelden von Audioprozessoren im \texttt{AudioHandlers} an. Die Methode \texttt{addProcessor()} fügt einen Audioprozessor in die Audioverarbeitungsliste ein, falls er noch nicht vorhanden ist, und \texttt{removeProcessor()} ist die entsprechende Löschmethode. Als Liste wird hier der Standardcontainer \texttt{std::vector} benutzt. Bei diesem werden neue Elemente am Ende der Liste eingefügt.

\begin{lstlisting}[caption={An- und Abmeldeprozess von Audioprozessoren im AudioHandler},label={Code:AudioHandlerAdd}]
bool AudioHandler::addProcessor(AudioProcessor *audioProcessor)
{
	if (hasAudioProcessor(audioProcessor) == false) {
		audioProcessors.push_back(std::unique_ptr<AudioProcessor>(audioProcessor));
		return true;
	}
	return false;
}

bool AudioHandler::removeAudioProcessor(AudioProcessor *audioProcessor) {
	for (size_t i = 0; i < audioProcessors.size(); i++)
	{
		if ((audioProcessors.at(i))->getName() == audioProcessor->getName()) {
			audioProcessors.erase(audioProcessors.begin() + i);
			return true;
		}	
	}
	return false;
}
\end{lstlisting}

\subsection{Verarbeitungsprozess}
Listening \ref{Code:AudioHandlerProcess} zeigt den Verarbeitungsprozess. Die Methode \texttt{processAudioInput()} wird vom AudioHandler aufgerufen, falls Daten vom Mikrofon zur Verarbeitung anliegen. Dort wird von jedem angemeldeten Audioprozessor die entsprechende \texttt{processInputData()} -Methode aufgerufen. Als Parameter werden die Daten des Mikrofons und deren Datengröße übergeben. Die Verarbeitungsreihenfolge entspricht der Anmeldereihenfolge. Die Verarbeitung im Buffer erfolgt in-place, daher auf den übergebenen Buffer. Falls ein Audioprozessor zu Beginn die Daten manipuliert, so sind diese Daten für alle nachfolgenden Prozessoren ebenfalls geändert. Im Umkehrschluss heißt dies, um wieder an die Ursprungsdaten zu gelangen, müssen die ausgeführten Änderungen in umgekehrte Reihenfolge rückgängig gemacht zu werden. \texttt{processAudioOutput()} wird aufgerufen, wenn die Soundkarte bereit ist Audiodaten abzuspielen. Hierzu werden von allen Audioprozessoren die \texttt{processOutputData()} - Methoden aufgerufen, jedoch mit umgekehrter Aufrufreihenfolge, siehe Zeile 13. Dadurch wird der Ursprungszustand der Audiodaten hergestellt und sind abspielbar.

\begin{lstlisting}[caption={Verarbeitungsprozess des AudioHandlers},label={Code:AudioHandlerProcess}]
void AudioHandler::processAudioInput(void *inputBuffer,  int inputBufferByteSize)
{
	unsigned int bufferSize = inputBufferByteSize;
	for (unsigned int i = 0; i < audioProcessors.size(); i++)
	{
		bufferSize = audioProcessors.at(i)->processInputData(inputBuffer, bufferSize);
	}
}

void AudioHandler::processAudioOutput(void *outputBuffer, int outputBufferByteSize)
{
	unsigned int bufferSize = outputBufferByteSize;
	for (unsigned int i = audioProcessors.size(); i > 0; i--)
	{
		bufferSize = audioProcessors.at(i-1)->processOutputData(outputBuffer, bufferSize);
	}
}
}\end{lstlisting}

\section{Factory-Klassen}
Die beiden Factory-Klassen \texttt{AudioHandlerFactory} und \texttt{AudioProcessorFactory} sind vom Aufbau identisch, deshalb wird im folgenden nur die \texttt{AudioHandlerFactory} erklärt. \texttt{AudioProcessorFactory} verhält sich analog dazu. Die Factory-Klassen haben die Aufgabe die Instantiierung in Methoden auszulagern, damit das Programmieren auf Schnittstellen gewährleistet wird. Methoden die Instantiierung übernehmen werden auch Fabrikmethoden genannt \cite{Goll2013}[S.243]. Listening \ref{Code:AudioHandlerFactory} zeigt die Fabrikmethode der \texttt{AudioHandlerFactory}. Als Parameter wird der Name der zu erzeugende Klasse entgegen genommen. Der Rückgabewert der Funktion entspricht den abstrakten und gemeinsamen Basistypen.

\begin{lstlisting}[caption={Fabrikmethode der AudioHandlerFactory},label={Code:AudioHandlerFactory}]
std::unique_ptr<AudioHandler> AudioHandlerFactory::getAudioHandler(std::string name) {
	if (name == RTAUDIO_WRAPPER)
	{
		std::unique_ptr<RtAudioWrapper> rtaudiowrapper(new RtAudioWrapper);
		return std::move(rtaudiowrapper);
	}
	throw std::invalid_argument("No AudioHandler for this name!");
}
\end{lstlisting}

\section{RTPListener}
\texttt{RTPListener} ermöglicht das asynchrone Empfangen von Paketen durch das Erstellen eines eignen Threads. Die wichtigsten Methoden der Klasse sind im Listening \ref{RTPListener} dargestellt. Die \texttt{startUp()}-Methode startet den Thread und \texttt{shutdown()} beendet ihn wieder. Sobald der Thread startet wird \texttt{runThread()} aufgerufen. Tatsächlich ist diese Methode komplexer, wurde jedoch für das Beispiel auf das wesentliche gekürzt. In der Schleife wird die blockierende \texttt{receiveData()}-Funktion aufgerufen. Übertragene Packete werden im Jitter-Buffer zwischengespeichert, siehe Zeile 14. Die empfangenen Pakete können anschließend aus dem Jitter-Buffer von anderen Threads ausgelesen werden. Der \texttt{RTPListener} wartet anschließend wieder auf neue ankommende Pakete.

\begin{lstlisting}[caption={Die wichtigsten Methoden des RTPListeners},label={Code:RTPListener}]
void RTPListener::startUp()
{
    threadRunning = true;
    receiveThread = std::thread(&RTPListener::runThread, this);
}

void RTPListener::shutdown(){
	threadRunning = false;
}

void RTPListener::runThread() {
	while(threadRunning) {
		int receivedSize = this->wrapper->receiveData(rtpHandler.getWorkBuffer(), rtpHandler.getMaximumPackageSize());
		auto result = buffer->addPackage(rtpHandler, receivedSize - RTP_HEADER_MIN_SIZE);
	}
}
\end{lstlisting}

\section{RTAudio}
(RTAUDIOWRAPPER) Callback-Methoden - Aufsplittung, Konfiguration von RTAudio, Aufruf der Callback-Methode durch die Hardware

\FloatBarrier
\section{Passive Konfiguration}
\label{passiveConfiguration}
Die passive Konfiguration aus Abschnitt \ref{configurationUsages} wird mithilfe von \textbf{Application-defined} RTCP-Paketen aus Abschnitt \ref{rtcp} umgesetzt. Hierfür wird für die Konfiguration einer Sitzung der Klient \textbf{A} mit der Option \enquote{Konfigurations-Anfrage aktivieren} (oder dem Parameter \texttt{--wait-for-passive}) gestartet, um eine Anfrage einer passiven Konfiguration zu ermöglichen. Klient \textbf{B} wird mit dem Parameter \texttt{--passive} ausgeführt. Klient \textbf{A} konfiguriert das OHMComm-Framework, startet jedoch noch keine Kommunikation, sondern nur den RTCP-Thread und wartet dort auf eine Anfrage für eine passive Konfiguration. Klient \textbf{B} sendet eine RTCP Application-defined Nachricht an \textbf{A}, die die Anfrage einer passiven Konfiguration darstellt. Daraufhin antwortet \textbf{A} mit einem weiteren RTCP-Paket, das die Werte der passiven Konfiguration (Abtastrate, Audioformat, Audiocodecs, Anzahl der Kanäle sowie die Puffergröße) beinhaltet. Dieses Paket wird von \textbf{B} empfangen und die Konfiguration ausgelesen. Daraufhin können beide Seiten das Übertragen von Audiodaten beginnen. Durch die Übertragung aller relevanten Informationen (Einstellungen der Audiobibliothek sowie die verwendeten Audiocodecs) wird garantiert, dass die gesendeten Daten von der anderen Instanz auch verstanden und verwendet werden können. Um die passive Konfiguration zu starten, wird für den Klienten \textbf{B} nur die IP-Adresse und der Port des Klienten \textbf{A} benötigt, wohingegen \textbf{A} komplett wie bereits beschrieben konfiguriert werden kann. Der Ablauf einer passiven Konfiguration ist schematisch in Listing \ref{lst:passiveConfiguration} dargestellt:
\newline
\begin{figure}[htp]
\centering
\includegraphics[width=.75\textwidth]{../img/passiveConfiguration}
\caption{Ablauf der passiven Konfiguration}
\label{lst:passiveConfiguration}
\end{figure}

\FloatBarrier
%\begin{lstlisting}[keepspaces=true,numbers=none,label=lst:passiveConfiguration,caption=Ablauf der passiven Konfiguration,xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
%Client B                            Client A
%  |                                       |
%  |         Konfigurationsanfrage         |
%  |-------------------------------------->|
%  |                                       |
%  |         passive Konfiguration         |
%  |<--------------------------------------|
%  |                                       |
%  |             Kommunikation             |
%  |<------------------------------------->|
%\end{lstlisting}